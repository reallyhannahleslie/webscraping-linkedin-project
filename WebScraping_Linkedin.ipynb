{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abc2be0d",
   "metadata": {},
   "source": [
    "## README\n",
    "\n",
    "### Task\n",
    "\n",
    "Scrape Data Science jobs in Barcelona from LinkedIn. \n",
    "\n",
    "\n",
    "### Approach\n",
    "\n",
    "Used selenium to navigate through LinkedIn and log in, then used predefined search link to access jobs. Finally scrapped data from LinkedIn.\n",
    "\n",
    "\n",
    "### Requirements\n",
    "* Selenium (pip install selenium)\n",
    "\n",
    "A Chrome Driver was used to thus you can download/update yours [here](https://chromedriver.chromium.org/downloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce95e448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchWindowException, StaleElementReferenceException, NoSuchElementException\n",
    "\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9cd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log in to Linkedin\n",
    "def login(driver, usr, pwd):\n",
    "    # Go to LinkedIn\n",
    "    driver.get('http://linkedin.com')\n",
    "    \n",
    "    # Let Selenium wait till the input field for the username shows up\n",
    "    WebDriverWait(driver, 30, 5).until(\n",
    "            EC.presence_of_element_located((By.ID, 'session_key'))\n",
    "        )\n",
    "\n",
    "    # Wait for 5 secs\n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    # Get input box for entering email and password\n",
    "    email = driver.find_element(By.ID, 'session_key')\n",
    "    password = driver.find_element(By.ID, 'session_password')\n",
    "    \n",
    "    # Enter email and password\n",
    "    email.send_keys(usr)\n",
    "    password.send_keys(pwd)\n",
    "\n",
    "    # Wait for 5 secs\n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    # Get the signin button\n",
    "    signin = driver.find_element(By.CLASS_NAME, 'sign-in-form__submit-button')\n",
    "    \n",
    "    # CLick the signin button\n",
    "    action = ActionChains(driver)\n",
    "    action.click(on_element=signin)\n",
    "    action.perform()\n",
    "    \n",
    "    # Let Selenium wait till the page loads up\n",
    "    WebDriverWait(driver, 30, 15).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, 'input'))\n",
    "        )\n",
    "    \n",
    "    driver.implicitly_wait(5)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b4cb120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchJobs(driver, url):\n",
    "    # Go to search page\n",
    "    driver.get(url)\n",
    "    \n",
    "    # Wait for page to load\n",
    "    WebDriverWait(driver, 30, 15).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"jobs-search-results-list\"))\n",
    "    )\n",
    "    \n",
    "    # Confirm that you're not on a company page and go back otherwise\n",
    "    try:\n",
    "        driver.find_element(By.CLASS_NAME, \"org-top-card__primary-content\")\n",
    "        driver.back()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Scrolling to end of the page\n",
    "    while True:\n",
    "        x = 250\n",
    "        driver.execute_script(f\"\"\"\n",
    "            container = document.querySelector('.jobs-search-results-list');\n",
    "            container.scrollBy(0, {x});\n",
    "            \"\"\")\n",
    "        driver.implicitly_wait(1) # Wait for 1sec for text and images to render properly\n",
    "\n",
    "        # Check the page for elements at the end of the page to verify of we've scrolled to the end/close\n",
    "        try:\n",
    "            pages = driver.find_element(By.CLASS_NAME, \"global-footer-compact__content\")\n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Get all the jobs listed in the left pane\n",
    "    selenium_jobs_list = driver.find_elements(By.CLASS_NAME, \"jobs-search-results__list-item\")\n",
    "    \n",
    "    return driver, selenium_jobs_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13451767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(driver, selenium_job_list):\n",
    "    job_titles = []\n",
    "    companies = []\n",
    "    locations = []\n",
    "    states = []\n",
    "    posting_dates = []\n",
    "    offer_urls = []\n",
    "    applicants_count = []\n",
    "    workspace_list = []\n",
    "    promotions = []\n",
    "    jobs = []\n",
    "    seniorities = []\n",
    "    emp_types = []\n",
    "    industries = []\n",
    "    python_reqs = []\n",
    "    easy_apply_list = []\n",
    "    employee_counts = []\n",
    "    followers_count = []\n",
    "\n",
    "    state_map = {\n",
    "        'early applicant': 'Early Applications',\n",
    "        'actively hiring': 'On-going',\n",
    "        'actively recruiting': 'On-going'\n",
    "    }\n",
    "\n",
    "    for job in selenium_jobs_list:\n",
    "        details_path = job.find_element(By.CLASS_NAME, 'job-card-list__title')\n",
    "    \n",
    "        # Extract job title\n",
    "        try:\n",
    "            job_title = job.find_element(By.CLASS_NAME, 'job-card-list__title').text\n",
    "        except: # Make job title None if it does not exist in the extracted page\n",
    "            job_title = None\n",
    "        job_titles.append(job_title)\n",
    "\n",
    "        # Extract company name\n",
    "        try:\n",
    "            company = job.find_element(By.CLASS_NAME, 'artdeco-entity-lockup__subtitle').text\n",
    "        except: # Make company None if it does not exist in the extracted page\n",
    "            company = None\n",
    "        companies.append(company)\n",
    "\n",
    "        # Extract job location\n",
    "        try:\n",
    "            location = job.find_element(By.CLASS_NAME, 'artdeco-entity-lockup__caption')\\\n",
    "                          .find_element(By.TAG_NAME, 'ul')\\\n",
    "                          .find_element(By.TAG_NAME, 'li')\\\n",
    "                          .text\n",
    "        except: # Make location None if it does not exist in the extracted page\n",
    "            location = None\n",
    "        locations.append(location)\n",
    "\n",
    "        # Extract the offer url for the job\n",
    "        try:\n",
    "            offer_url = job.find_element(By.CLASS_NAME, 'job-card-container__link').get_property('href')\n",
    "        except:\n",
    "            offer_url = None\n",
    "        offer_urls.append(offer_url)\n",
    "\n",
    "        # Extract the workspace for the job\n",
    "        try:\n",
    "            workspace = job.find_element(By.CLASS_NAME, 'job-card-container__metadata-item--workplace-type').text \n",
    "        except:\n",
    "            workspace = None\n",
    "        workspace_list.append(workspace)\n",
    "\n",
    "        # Extract the promotion status of the job\n",
    "        try:\n",
    "            promoted = job.find_element(By.CLASS_NAME, 'job-card-list__footer-wrapper').text\n",
    "            promoted = True if 'Promoted' in promoted else False\n",
    "        except:\n",
    "            promoted = False\n",
    "        promotions.append(promoted)\n",
    "\n",
    "        # Click on job on the page to get the job details\n",
    "        details_path.click()\n",
    "\n",
    "        try:\n",
    "            # Wait for page to load\n",
    "            WebDriverWait(driver, 30, 15).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME, 'jobs-search__job-details--container'))\n",
    "            )\n",
    "\n",
    "            # Get details section of job from the right pane\n",
    "            details = driver.find_element(By.CLASS_NAME, 'jobs-search__job-details--container')\n",
    "        except:\n",
    "            driver.back()\n",
    "\n",
    "\n",
    "        # Extract job posting date\n",
    "        try:\n",
    "            date = details.find_element(By.CLASS_NAME, 'jobs-unified-top-card__posted-date').text\n",
    "        except:\n",
    "            date = None\n",
    "        posting_dates.append(date)\n",
    "\n",
    "        # Get number of applicants that applied to job\n",
    "        try:\n",
    "            applicant_number = details.find_element(By.CLASS_NAME, 'jobs-unified-top-card__applicant-count').text\n",
    "            applicants = int(re.findall(r'\\d+', applicant_number)[0]) # Extract number from text\n",
    "        except:\n",
    "            try:\n",
    "                applicant_number = details.find_element(By.CLASS_NAME, 'jobs-unified-top-card__applicant-count').text\n",
    "                applicants = int(re.findall(r'\\d+', applicant_number)[0]) # Extract number from text\n",
    "            except:\n",
    "                applicants = None\n",
    "\n",
    "        applicants_count.append(applicants)\n",
    "\n",
    "        seniority = None\n",
    "        emp_type = None\n",
    "        industry = None\n",
    "        employees = None\n",
    "        state = None\n",
    "\n",
    "        try:\n",
    "            role_insights = details.find_elements(By.CLASS_NAME, 'jobs-unified-top-card__job-insight')\n",
    "            senior_emp = role_insights[0].text.split('·')\n",
    "\n",
    "            # Get seniority and employment type\n",
    "            if len(senior_emp) > 1: # 2 role insights stated (seniority and employment type)\n",
    "                seniority = senior_emp[1].strip()\n",
    "            emp_type = senior_emp[0].strip()\n",
    "\n",
    "            emp_industry = role_insights[1].text.split('·')\n",
    "\n",
    "            # Get number of employee and industry\n",
    "            if len(emp_industry) > 1: # 2 role insights stated (number of employees and industry)\n",
    "                industry = emp_industry[1].strip()\n",
    "            employees = emp_industry[0].strip().split('-')[0]\n",
    "            employees = int(''.join(re.findall(r'\\d+', employees))) # Extract numbers from text\n",
    "\n",
    "            # Extract job state\n",
    "            try:\n",
    "                state = role_insights[-1].text.lower()\n",
    "            except AttributeError: # Make state None if it does not exist in the extracted page\n",
    "                state = 'others'\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        seniorities.append(seniority)\n",
    "        emp_types.append(emp_type)\n",
    "        industries.append(industry)\n",
    "        employee_counts.append(employees)\n",
    "        states.append(state_map.get(state) if state_map.get(state) else 'Others')\n",
    "\n",
    "        # Check if you can apply through linkedin\n",
    "        try:\n",
    "            easy_apply = details.find_element(By.CLASS_NAME, 'jobs-apply-button').text.lower()\n",
    "            easy_apply = True if easy_apply == 'easy apply' else False\n",
    "        except:\n",
    "            easy_apply = False\n",
    "        easy_apply_list.append(easy_apply)\n",
    "\n",
    "        # Check if python is required for the job\n",
    "        try:\n",
    "            description = details.find_element(By.CLASS_NAME, 'jobs-description__content').text.lower()\n",
    "            python_req = True if 'python' in description else False\n",
    "        except:\n",
    "            python_req = False\n",
    "        python_reqs.append(python_req)\n",
    "\n",
    "        scroll_time = time.time()\n",
    "\n",
    "        # Scrolling to end of the page\n",
    "        while True:\n",
    "            try:\n",
    "                x = 250\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    container = document.querySelector('.jobs-search__job-details--container');\n",
    "                    container.scrollBy(0, {x});\n",
    "                    \"\"\")\n",
    "                driver.implicitly_wait(1) # Wait for 1sec for text and images to render properly\n",
    "\n",
    "                # Check the page for elements at the end of the page to verify of we've scrolled to the end/close\n",
    "                pages = driver.find_element(By.CLASS_NAME, 'jobs-company__footer')\n",
    "                company_details = driver.find_element(By.CLASS_NAME, 'jobs-company__box')\n",
    "\n",
    "                driver.execute_script(f\"\"\"\n",
    "                    container = document.querySelector('.jobs-search__job-details--container');\n",
    "                    container.scrollBy(0, {x});\n",
    "                    \"\"\")\n",
    "\n",
    "                # Get details section of job from the right pane again\n",
    "                details = driver.find_element(By.CLASS_NAME, 'jobs-search__job-details--container')\n",
    "\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if (time.time() - scroll_time) > 30: break # Stop scrolling if you've been on the page for more than 30s\n",
    "\n",
    "        # Get the number of followers the company has\n",
    "        try:\n",
    "            company_details = details.find_element(By.CLASS_NAME, 'jobs-company__box')\n",
    "            followers = company_details.find_element(By.CLASS_NAME, 'artdeco-entity-lockup__subtitle').text\n",
    "            followers_count.append(int(''.join(re.findall(r'\\d+', followers))))\n",
    "        except:\n",
    "            followers_count.append(None)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'Job Title': job_titles, \n",
    "        'Company Name': companies, \n",
    "        'Location': locations, \n",
    "        'State': states, \n",
    "        'Posting Date': posting_dates, \n",
    "        'Offer URL': offer_urls, \n",
    "        'Number of Applicants': applicants_count,\n",
    "        'Promoted': promotions,\n",
    "        'Workspace': workspace_list, \n",
    "        'Seniority': seniorities, \n",
    "        'Employment Type': emp_types, \n",
    "        'Industry': industries, \n",
    "        'Python Required': python_reqs,\n",
    "        'Application through Linkedin': easy_apply_list,\n",
    "        'Number of Employees': employee_counts,\n",
    "        'Followers': followers_count\n",
    "    })\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee87904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "usr = 'kdodor@ymail.com'\n",
    "pwd = 'A$$1gnm€nt'\n",
    "\n",
    "driver = webdriver.Chrome('./chromedriver')\n",
    "driver = login(driver, usr, pwd)\n",
    "\n",
    "url = 'https://www.linkedin.com/jobs/search/?keywords=data scientist, barcelona&location=Barcelona, Catalonia, Spain&refresh=true'\n",
    "page_start = 25\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "start_extract = time.time()\n",
    "print('Begin Extraction')\n",
    "while page_start <= 1000:\n",
    "    print(f'Scrapping Data From Page: {page_start/25}')\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        driver, selenium_jobs_list = searchJobs(driver, url)\n",
    "        print(f'Search time = {(time.time() - start_time)/60}mins')\n",
    "        \n",
    "        data_extract_start = time.time()\n",
    "        data = getData(driver, selenium_jobs_list)\n",
    "        print(f'Data Extraction time = {(time.time() - data_extract_start)/60}mins')\n",
    "        df = pd.concat([df, data], ignore_index=True)\n",
    "        \n",
    "        start = driver.current_url.find('&start') if driver.current_url.find('&start') > 0 else len(driver.current_url)\n",
    "        url = f'{driver.current_url[:start]}&start={page_start}'\n",
    "        \n",
    "        end_time = (time.time() - start_time)\n",
    "        print('Extraction duration:', end_time/60, 'mins')\n",
    "        print(url)\n",
    "        print(page_start)\n",
    "        print(df.isna().sum())\n",
    "        \n",
    "        page_start += 25\n",
    "    except (NoSuchWindowException, StaleElementReferenceException, NoSuchElementException, ValueError):\n",
    "        print('Retrying')\n",
    "        continue\n",
    "    except Exception as e:\n",
    "        print('Quitting')\n",
    "        break\n",
    "        \n",
    "print(f'Total Extraction time:{(time.time() - start_extract)/3600}hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9db49185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 970 entries, 0 to 969\n",
      "Data columns (total 16 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   Job Title                     970 non-null    object \n",
      " 1   Company Name                  970 non-null    object \n",
      " 2   Location                      970 non-null    object \n",
      " 3   State                         970 non-null    object \n",
      " 4   Posting Date                  970 non-null    object \n",
      " 5   Offer URL                     970 non-null    object \n",
      " 6   Number of Applicants          880 non-null    float64\n",
      " 7   Promoted                      970 non-null    bool   \n",
      " 8   Workspace                     730 non-null    object \n",
      " 9   Seniority                     792 non-null    object \n",
      " 10  Employment Type               970 non-null    object \n",
      " 11  Industry                      927 non-null    object \n",
      " 12  Python Required               970 non-null    bool   \n",
      " 13  Application through Linkedin  970 non-null    bool   \n",
      " 14  Number of Employees           970 non-null    int64  \n",
      " 15  Followers                     968 non-null    float64\n",
      "dtypes: bool(3), float64(2), int64(1), object(10)\n",
      "memory usage: 101.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e29146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
